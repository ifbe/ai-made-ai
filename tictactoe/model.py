# model.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import numpy as np

class FearGreedModel(nn.Module):
    """ææƒ§ä¸è´ªå©ªæ¨¡å‹ - å¯å­¦ä¹ çš„ä¼˜å…ˆçº§èåˆ"""
    def __init__(self, d_model=128, nhead=4, num_layers=4, dim_feedforward=512, dropout=0.1):
        super().__init__()
        
        self.d_model = d_model
        
        # åŸºç¡€åµŒå…¥
        self.state_embedding = nn.Embedding(3, d_model)  # 0=ç©º, 1=X, 2=O
        self.pos_embedding = nn.Parameter(torch.randn(1, 9, d_model) * 0.02)
        self.turn_embedding = nn.Embedding(2, d_model)  # 0=Xå…ˆæ‰‹, 1=Oåæ‰‹
        
        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True,
            activation='gelu'
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
        
        # LayerNorm
        self.norm = nn.LayerNorm(d_model)
        
        # ææƒ§å¤´ - è¾“å‡ºç‰¹å¾
        self.fear_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # è´ªå©ªå¤´ - è¾“å‡ºç‰¹å¾
        self.greed_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # æ™®é€šç­–ç•¥å¤´ - è¾“å‡ºç‰¹å¾
        self.normal_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # ä¼˜å…ˆçº§èåˆå±‚ - ç›´æ¥è¾“å‡ºæœ€ç»ˆç­–ç•¥
        self.fusion_layer = nn.Sequential(
            nn.Linear(d_model * 3 // 2, d_model),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, 9)
        )
        
        # ä»·å€¼å¤´ - å±€é¢è¯„ä¼°
        self.value_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 1),
            nn.Tanh()
        )
        
        # æ³¨æ„åŠ›å¤´ - ç”¨äºå¯è§†åŒ–
        self.attention_head = nn.Sequential(
            nn.Linear(d_model * 3 // 2, 1),
            nn.Sigmoid()
        )
        
        self._init_weights()
    
    def _init_weights(self):
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)
    
    def forward(self, board, turn=None, return_details=False):
        batch_size = board.size(0)
        
        # åµŒå…¥
        emb = self.state_embedding(board) * math.sqrt(self.d_model)
        emb = emb + self.pos_embedding
        
        # æ·»åŠ turnä¿¡æ¯
        if turn is not None:
            turn_emb = self.turn_embedding(turn).unsqueeze(1)
            emb = torch.cat([turn_emb, emb], dim=1)
            has_turn = True
        else:
            has_turn = False
        
        # Encoder
        memory = self.encoder(emb)
        memory = self.norm(memory)
        
        # æå–ä½ç½®ç‰¹å¾
        if has_turn:
            position_features = memory[:, 1:, :]
            global_feat = memory[:, 0, :]
        else:
            position_features = memory
            global_feat = memory.mean(dim=1)
        
        # ä¸‰ä¸ªä¸“å®¶å¤´æå–ç‰¹å¾
        fear_features = self.fear_head(position_features)
        greed_features = self.greed_head(position_features)
        normal_features = self.normal_head(position_features)
        
        # æ‹¼æ¥ä¸‰ä¸ªå¤´çš„ç‰¹å¾
        combined_features = torch.cat([
            fear_features, 
            greed_features, 
            normal_features
        ], dim=-1)
        
        # å¯¹æ¯ä¸ªä½ç½®å–å¹³å‡ï¼Œå¾—åˆ°å…¨å±€ç‰¹å¾
        global_combined = combined_features.mean(dim=1)
        
        # ä¼˜å…ˆçº§èåˆå±‚ - ç›´æ¥è¾“å‡ºæœ€ç»ˆç­–ç•¥
        final_policy = self.fusion_layer(global_combined)
        
        # ä»·å€¼è¯„ä¼°
        value = self.value_head(global_feat)
        
        # æ³¨æ„åŠ›åˆ†æ•°ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        attention = self.attention_head(global_combined)
        
        if return_details:
            fear_scores = fear_features.mean(dim=-1)
            greed_scores = greed_features.mean(dim=-1)
            
            return {
                'policy': final_policy,
                'value': value,
                'fear_features': fear_features,
                'greed_features': greed_features,
                'normal_features': normal_features,
                'fear_scores': fear_scores,
                'greed_scores': greed_scores,
                'attention': attention,
                'global_feat': global_feat
            }
        
        return final_policy, value
    
    def decide_move(self, board, player, device='cpu', debug=False):
        self.eval()
        with torch.no_grad():
            board_tensor = torch.tensor(board, dtype=torch.long, device=device).unsqueeze(0)
            turn = torch.tensor([0 if player == 1 else 1], device=device)
            
            details = self.forward(board_tensor, turn, return_details=True)
            
            policy = F.softmax(details['policy'][0], dim=-1).cpu().numpy()
            fear_scores = details['fear_scores'][0].cpu().numpy()
            greed_scores = details['greed_scores'][0].cpu().numpy()
            value = details['value'][0].item()
            attention = details['attention'][0].item()
            
            from game import get_legal_moves
            legals = get_legal_moves(board)
            
            valid_policy = policy.copy()
            for i in range(9):
                if i not in legals:
                    valid_policy[i] = 0
            if valid_policy.sum() > 0:
                valid_policy = valid_policy / valid_policy.sum()
            else:
                valid_policy[legals[0]] = 1.0
            
            best_move = valid_policy.argmax()
            
            if debug:
                print(f"\nğŸ“Š ä¼˜å…ˆçº§èåˆç»“æœ:")
                print(f"   æ³¨æ„åŠ›å€¼: {attention:.4f}")
                print("\n   ææƒ§åˆ†æ•°:")
                for i in range(3):
                    row = ""
                    for j in range(3):
                        idx = i * 3 + j
                        row += f" {fear_scores[idx]:.2f} "
                    print(f"      {row}")
                print("\n   è´ªå©ªåˆ†æ•°:")
                for i in range(3):
                    row = ""
                    for j in range(3):
                        idx = i * 3 + j
                        row += f" {greed_scores[idx]:.2f} "
                    print(f"      {row}")
            
            return {
                'move': best_move,
                'policy': valid_policy,
                'fear': fear_scores,
                'greed': greed_scores,
                'value': value,
                'attention': attention
            }
