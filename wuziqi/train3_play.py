import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•

# play.py
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import os
import glob
import json
import time
from datetime import datetime
from model import FearGreedWuziqiModel
from game import (
    check_win, is_full, get_legal_moves, get_nearby_moves,
    BLACK, WHITE, EMPTY, BOARD_SIZE, pos_to_str, str_to_pos
)

# åˆ›å»º stage3 ç›®å½•ï¼ˆç”¨äºå­˜æ”¾å¾®è°ƒæ¨¡å‹ï¼‰
os.makedirs("stage3", exist_ok=True)

# å¯¹å±€å†å²æ–‡ä»¶å
PLAY_HISTORY_FILE = "history_play.json"

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def print_board(board, last_move=None, title=None):
    """æ‰“å°æ£‹ç›˜"""
    if title:
        print(f"\n{title}")
    
    print("\n   ", end="")
    for i in range(BOARD_SIZE):
        if i < 10:
            print(f"â”‚ {i} ", end="")
        else:
            print(f"â”‚ {chr(ord('a') + (i-10))} ", end="")
    print("â”‚")
    
    print("   " + "â”œâ”€â”€â”€" * BOARD_SIZE + "â”¤")
    
    for i in range(BOARD_SIZE):
        if i < 10:
            print(f" {i} ", end="")
        else:
            print(f" {chr(ord('a') + (i-10))} ", end="")
        
        for j in range(BOARD_SIZE):
            idx = i * BOARD_SIZE + j
            val = board[idx]
            
            if val == BLACK:
                piece = "X"
            elif val == WHITE:
                piece = "O"
            else:
                piece = " "
            
            if last_move is not None and last_move == idx:
                print(f"â”‚\033[7m{piece:^3}\033[0m", end="")
            else:
                print(f"â”‚{piece:^3}", end="")
        
        print("â”‚")
        
        if i < BOARD_SIZE - 1:
            print("   " + "â”œâ”€â”€â”€" * BOARD_SIZE + "â”¤")
    
    print("   " + "â””â”€â”€â”€" * BOARD_SIZE + "â”˜")

def print_heatmap_grid(board, scores, title):
    """æ‰“å°çƒ­åŠ›å›¾"""
    if title:
        print(f"\n{title}")
    
    print("\n   ", end="")
    for i in range(BOARD_SIZE):
        if i < 10:
            print(f"â”‚ {i} ", end="")
        else:
            print(f"â”‚ {chr(ord('a') + (i-10))} ", end="")
    print("â”‚")
    
    print("   " + "â”œâ”€â”€â”€" * BOARD_SIZE + "â”¤")
    
    for i in range(BOARD_SIZE):
        if i < 10:
            print(f" {i} ", end="")
        else:
            print(f" {chr(ord('a') + (i-10))} ", end="")
        
        for j in range(BOARD_SIZE):
            idx = i * BOARD_SIZE + j
            score = scores[idx]
            
            if board[idx] != EMPTY:
                piece = "X" if board[idx] == BLACK else "O"
                print(f"â”‚ \033[90m{piece}\033[0m ", end="")
            else:
                if score > 0.7:
                    print(f"â”‚\033[91m{score:.1f}\033[0m", end="")
                elif score > 0.4:
                    print(f"â”‚\033[93m{score:.1f}\033[0m", end="")
                elif score > 0.1:
                    print(f"â”‚\033[92m{score:.1f}\033[0m", end="")
                else:
                    print(f"â”‚{score:.1f}", end="")
        
        print("â”‚")
        
        if i < BOARD_SIZE - 1:
            print("   " + "â”œâ”€â”€â”€" * BOARD_SIZE + "â”¤")
    
    print("   " + "â””â”€â”€â”€" * BOARD_SIZE + "â”˜")

def print_analysis(decision, player, board):
    """æ‰“å°è¯¦ç»†åˆ†æ"""
    print("\n" + "=" * 100)
    print(f"ğŸ¤– æ¨¡å‹åˆ†æ (è½®åˆ° {'é»‘æ£‹(X)' if player == BLACK else 'ç™½æ£‹(O)'})")
    print("=" * 100)
    
    value = decision.get('value', 0)
    print(f"\nğŸ“ˆ å±€é¢ä»·å€¼: {value:+.4f} ", end="")
    if value > 0.3:
        print("(é»‘æ£‹æ˜æ˜¾ä¼˜åŠ¿)")
    elif value > 0.1:
        print("(é»‘æ£‹ç•¥ä¼˜)")
    elif value < -0.3:
        print("(ç™½æ£‹æ˜æ˜¾ä¼˜åŠ¿)")
    elif value < -0.1:
        print("(ç™½æ£‹ç•¥ä¼˜)")
    else:
        print("(å‡åŠ¿)")
    
    attention = decision.get('attention', 0.5)
    print(f"\nâš–ï¸  ææƒ§/è´ªå©ªå¹³è¡¡: {attention:.3f} ", end="")
    if attention > 0.6:
        print("(åå‘è¿›æ”»)")
    elif attention < 0.4:
        print("(åå‘é˜²å®ˆ)")
    else:
        print("(å¹³è¡¡)")
    
    if 'fear' in decision:
        print_heatmap_grid(board, decision['fear'], "\nğŸ˜¨ ææƒ§åˆ†æ•° (å¯¹æ‰‹å¨èƒ):")
    
    if 'greed' in decision:
        print_heatmap_grid(board, decision['greed'], "\nğŸ’° è´ªå©ªåˆ†æ•° (è‡ªå·±æœºä¼š):")
    
    if 'normal' in decision:  # ç¬¬ä¸‰ä¸ªå¤´
        print_heatmap_grid(board, decision['normal'], "\nğŸ“Š æ™®é€šç­–ç•¥åˆ†æ•° (åŸºç¡€èµ°æ³•):")
    
    if 'policy' in decision:
        print_heatmap_grid(board, decision['policy'], "\nğŸ¯ æœ€ç»ˆç­–ç•¥ (èåˆå):")
    
    print(f"\nâœ… æœ€ç»ˆé€‰æ‹©: {pos_to_str(decision['move'])}")
    print("=" * 100)

def find_best_model():
    """æŸ¥æ‰¾æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆstage3ï¼Œç„¶åstage2ï¼ˆå–epochæœ€å¤§ï¼‰ï¼Œæœ€åstage0ï¼ˆå–å‡†ç¡®ç‡æœ€é«˜ï¼‰"""
    # 1. ä¼˜å…ˆæ‰¾stage3çš„å¾®è°ƒæ¨¡å‹ï¼ˆå–æœ€æ–°çš„ï¼‰
    stage3_files = glob.glob("stage3/wuziqi_stage3_*.pth")
    if stage3_files:
        latest = max(stage3_files, key=os.path.getctime)
        return latest, "stage3"
    
    # 2. å…¶æ¬¡æ‰¾stage2çš„æ¨¡å‹ï¼ˆå–epochæœ€å¤§çš„ï¼Œå› ä¸ºevaluateä¸å‡†ï¼‰
    stage2_files = glob.glob("stage2/wuziqi_stage2_checkpoint_epoch*.pth")
    if stage2_files:
        # ä»æ–‡ä»¶åæå–epochå·ï¼Œå–æœ€å¤§çš„
        best_model = None
        max_epoch = 0
        for f in stage2_files:
            try:
                epoch_str = f.split('epoch')[1].split('.')[0]
                epoch = int(epoch_str)
                if epoch > max_epoch:
                    max_epoch = epoch
                    best_model = f
            except:
                continue
        if best_model:
            return best_model, f"stage2 (epoch {max_epoch})"
    
    # 3. ç„¶åæ‰¾stage0çš„æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰å‡†ç¡®ç‡ï¼‰
    stage0_files = glob.glob("stage0/wuziqi_stage0_best_*.pth")
    if stage0_files:
        best_model = None
        best_acc = 0
        for f in stage0_files:
            try:
                acc_str = f.split('best_')[1].split('%')[0]
                acc = float(acc_str)
                if acc > best_acc:
                    best_acc = acc
                    best_model = f
            except:
                continue
        if best_model:
            return best_model, f"stage0 (acc {best_acc}%)"
    
    # 4. æœ€åæ‰¾finalæ¨¡å‹
    final_files = glob.glob("stage2/wuziqi_stage2_final.pth") + glob.glob("stage0/wuziqi_stage0_final.pth")
    if final_files:
        return final_files[0], "final"
    
    return None, None

def save_game_to_file(game_data, filename=PLAY_HISTORY_FILE):
    """ä¿å­˜å¯¹å±€åˆ°æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰"""
    games = []
    
    if os.path.exists(filename):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                games = json.load(f)
        except:
            games = []
    
    games.append(game_data)
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(games, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å¯¹å±€å·²ä¿å­˜åˆ° {filename}")

def fine_tune_from_game(model, game_data, device, lr=1e-5):
    """ç”¨ç©å®¶å¯¹å±€æ•°æ®å¾®è°ƒæ¨¡å‹"""
    # å¯¼å…¥éœ€è¦çš„å¸¸é‡
    from game import BOARD_POSITIONS, EMPTY, BLACK, WHITE, get_nearby_moves, str_to_pos
    
    model.train()
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)
    
    moves = game_data['moves']
    winner = game_data['winner']
    
    # è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®
    boards = []
    players = []
    actions = []
    rewards = []
    
    board = [EMPTY] * BOARD_POSITIONS
    current_player = BLACK  # 1
    
    for step, (pos_str, player_str) in enumerate(moves):
        pos = str_to_pos(pos_str)
        if pos is None:
            continue
        
        # è®°å½•è¿™ä¸€æ­¥
        boards.append(board.copy())
        # è½¬æ¢ï¼šBLACK(1) -> 0, WHITE(2) -> 1
        players.append(0 if current_player == BLACK else 1)
        actions.append(pos)
        
        # æ ¹æ®èƒœè´Ÿè®¡ç®—å¥–åŠ±
        if winner == 'player':
            # ç©å®¶èµ¢äº†ï¼šç©å®¶çš„æ¯ä¸€æ­¥éƒ½æ˜¯å¥½çš„ï¼ŒAIçš„æ¯ä¸€æ­¥éƒ½æ˜¯åçš„
            if (player_str == 'black' and game_data['player_color'] == 'black') or \
               (player_str == 'white' and game_data['player_color'] == 'white'):
                reward = 0.1  # ç©å®¶çš„å¥½æ£‹
            else:
                reward = -0.1  # AIçš„åæ£‹
        elif winner == 'ai':
            # AIèµ¢äº†ï¼šAIçš„æ¯ä¸€æ­¥éƒ½æ˜¯å¥½çš„ï¼Œç©å®¶çš„æ¯ä¸€æ­¥éƒ½æ˜¯åçš„
            if (player_str == 'black' and game_data['ai_color'] == 'black') or \
               (player_str == 'white' and game_data['ai_color'] == 'white'):
                reward = 0.1  # AIçš„å¥½æ£‹
            else:
                reward = -0.1  # ç©å®¶çš„åæ£‹
        else:
            reward = 0.0  # å¹³å±€
        
        rewards.append(reward)
        
        # æ›´æ–°æ£‹ç›˜
        board[pos] = current_player
        current_player = 3 - current_player
    
    # è½¬æ¢ä¸ºtensor
    boards_tensor = torch.tensor(boards, dtype=torch.long, device=device)
    players_tensor = torch.tensor(players, dtype=torch.long, device=device)
    actions_tensor = torch.tensor(actions, device=device)
    rewards_tensor = torch.tensor(rewards, dtype=torch.float, device=device)
    
    # è®­ç»ƒå‡ æ­¥
    model.train()
    total_loss = 0
    
    for i in range(0, len(boards), 16):  # batch_size=16
        batch_boards = boards_tensor[i:i+16]
        batch_players = players_tensor[i:i+16]
        batch_actions = actions_tensor[i:i+16]
        batch_rewards = rewards_tensor[i:i+16]
        
        # è·å–é™„è¿‘ä½ç½®ä½œä¸ºåˆæ³•ç§»åŠ¨
        legal_moves_list = []
        for b in range(len(batch_boards)):
            board_state = batch_boards[b].cpu().numpy()
            nearby = get_nearby_moves(board_state, distance=2)
            if not nearby:
                center = BOARD_SIZE // 2
                nearby = [center * BOARD_SIZE + center]
            legal_moves_list.append(nearby)
        
        policy_logits, values = model.forward_with_mask(
            batch_boards, batch_players, legal_moves=legal_moves_list
        )
        
        log_probs = F.log_softmax(policy_logits, dim=-1)
        action_log_probs = log_probs.gather(1, batch_actions.unsqueeze(1)).squeeze()
        
        advantages = batch_rewards - values.squeeze()
        policy_loss = -(action_log_probs * advantages.detach()).mean()
        value_loss = F.mse_loss(values.squeeze(-1), batch_rewards)
        
        loss = policy_loss + 0.5 * value_loss
        
        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)
        optimizer.step()
        
        total_loss += loss.item()
    
    model.eval()
    print(f"   ğŸ¤– å¾®è°ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {total_loss/len(boards):.4f}")
    
    # ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹åˆ° stage3 ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = f"stage3/wuziqi_stage3_{timestamp}.pth"
    torch.save(model.cpu().state_dict(), model_path)
    model.to(device)
    print(f"   ğŸ’¾ å¾®è°ƒæ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    return model

def load_model(model_path, device):
    """åŠ è½½æ¨¡å‹ - æ”¯æŒæ™®é€šæƒé‡å’Œcheckpoint"""
    model = FearGreedWuziqiModel(
        d_model=128,
        nhead=4,
        num_layers=2,
        dim_feedforward=256
    ).to(device)
    
    try:
        checkpoint = torch.load(model_path, map_location=device)
        
        # åˆ¤æ–­æ˜¯checkpointè¿˜æ˜¯çº¯æƒé‡
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            # è¿™æ˜¯checkpointæ–‡ä»¶
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… åŠ è½½checkpointæ¨¡å‹: {model_path}")
            if 'epoch' in checkpoint:
                print(f"   epoch: {checkpoint['epoch']}")
            if 'best_win_rate' in checkpoint:
                print(f"   æœ€ä½³èƒœç‡: {checkpoint['best_win_rate']:.2%}")
        else:
            # è¿™æ˜¯çº¯æƒé‡æ–‡ä»¶
            model.load_state_dict(checkpoint)
            print(f"âœ… åŠ è½½æƒé‡æ¨¡å‹: {model_path}")
        
        return model
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å¤±è´¥: {e}")
        return None

def play():
    clear_screen()
    print("=" * 100)
    print("ğŸ® äº”å­æ£‹ææƒ§ä¸è´ªå©ª AI")
    print("=" * 100)
    print("\nğŸ“ è¾“å…¥æ ¼å¼: ä¸¤ä¸ªå­—ç¬¦ï¼Œå¦‚ 00 è¡¨ç¤ºå·¦ä¸Šè§’")
    print("   åˆ—: 0-9 a-e")
    print("   è¡Œ: 0-9 a-e")
    print("\næ£‹å­: X = é»‘æ£‹, O = ç™½æ£‹")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ’» ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹ï¼ˆä¼˜å…ˆstage3ï¼‰
    model_path, model_type = find_best_model()
    if model_path:
        model = load_model(model_path, device)
        print(f"   ä½¿ç”¨ {model_type} æ¨¡å‹")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
        model = FearGreedWuziqiModel(
            d_model=128,
            nhead=4,
            num_layers=2,
            dim_feedforward=256
        ).to(device)
    
    print("\né€‰æ‹©å…ˆåæ‰‹:")
    print("   1. æˆ‘å…ˆæ‰‹ (é»‘æ£‹ X)")
    print("   2. AIå…ˆæ‰‹ (ç™½æ£‹ O)")
    
    while True:
        choice = input("\nè¯·è¾“å…¥ (1/2): ").strip()
        if choice in ['1', '2']:
            break
        print("è¾“å…¥æ— æ•ˆ")
    
    human_first = (choice == '1')
    
    board = [EMPTY] * (BOARD_SIZE * BOARD_SIZE)
    current_player = BLACK
    last_move = None
    moves_history = []  # è®°å½•å¯¹å±€å†å²
    
    clear_screen()
    print("\nğŸ® æ¸¸æˆå¼€å§‹!")
    print_board(board)
    
    while True:
        if check_win(board, BLACK):
            winner = "black"
            winner_str = "é»‘æ£‹"
            break
        if check_win(board, WHITE):
            winner = "white"
            winner_str = "ç™½æ£‹"
            break
        if is_full(board):
            winner = "draw"
            winner_str = "å¹³å±€"
            break
        
        is_human = (current_player == BLACK and human_first) or \
                   (current_player == WHITE and not human_first)
        
        if is_human:
            print(f"\nğŸ‘¤ è½®åˆ°ä½ äº† ({'é»‘æ£‹(X)' if current_player == BLACK else 'ç™½æ£‹(O)'})")
            
            legals = get_legal_moves(board)
            nearby = get_nearby_moves(board, distance=2)
            print(f"æ¨èè½å­åŒºåŸŸ: {[pos_to_str(p) for p in nearby[:5]]}")
            
            while True:
                try:
                    pos_str = input("è¯·é€‰æ‹©ä½ç½® (å¦‚ 00): ").strip()
                    pos = str_to_pos(pos_str)
                    if pos is None:
                        print("âŒ æ ¼å¼é”™è¯¯")
                    elif pos not in legals:
                        print(f"âŒ ä½ç½® {pos_str} ä¸åˆæ³•")
                    else:
                        break
                except KeyboardInterrupt:
                    print("\n\næ¸¸æˆç»“æŸ")
                    return
            
            board[pos] = current_player
            moves_history.append((pos_str, 'black' if current_player == BLACK else 'white'))
            last_move = pos
            
            clear_screen()
            print_board(board, last_move)
            
        else:
            print(f"\nğŸ¤– AI æ€è€ƒä¸­...")
            
            decision = model.decide_move_fast(board, current_player, device, debug=False)
            
            clear_screen()
            print_board(board, last_move)
            print_analysis(decision, current_player, board)
            
            pos = decision['move']
            pos_str = pos_to_str(pos)
            board[pos] = current_player
            moves_history.append((pos_str, 'black' if current_player == BLACK else 'white'))
            last_move = pos
            
            print(f"\nâœ… AI é€‰æ‹©äº† {pos_str}")
            print_board(board, last_move)
        
        current_player = 3 - current_player
    
    # æ¸¸æˆç»“æŸï¼Œæ˜¾ç¤ºç»“æœ
    print(f"\nğŸ† æ¸¸æˆç»“æŸ! èƒœè€…: {winner_str}")
    print_board(board, last_move)
    
    # ä¿å­˜å¯¹å±€å†å²
    game_data = {
        'timestamp': datetime.now().isoformat(),
        'player_color': 'black' if human_first else 'white',
        'ai_color': 'white' if human_first else 'black',
        'winner': 'player' if (winner == 'black' and human_first) or (winner == 'white' and not human_first) else
                 'ai' if (winner == 'black' and not human_first) or (winner == 'white' and human_first) else
                 'draw',
        'moves': moves_history
    }
    
    save_game_to_file(game_data)
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­
    while True:
        again = input("\nå†ç©ä¸€å±€ï¼Ÿ(y/n/t): ").strip().lower()
        if again in ['y', 'n', 't']:
            break
        print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ y(æ˜¯)/n(å¦)/t(è®­ç»ƒ)")
    
    if again == 'y':
        play()
    elif again == 't':
        print(f"\nğŸ”„ æ­£åœ¨ç”¨æœ¬å±€æ•°æ®å¾®è°ƒæ¨¡å‹...")
        model = fine_tune_from_game(model, game_data, device)
        # å¾®è°ƒåè‡ªåŠ¨å¼€å§‹æ–°ä¸€å±€
        play()
    else:
        print("\nğŸ‘‹ æ„Ÿè°¢æ¸¸ç©ï¼Œå†è§ï¼")

if __name__ == "__main__":
    play()
